# -*- coding: utf-8 -*-
"""Redes_convolucionales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t7W_wN5Nj5mhTMTLBRlhGtp8n5pyLrE7

<h1><font color="#113D68" size=5>Redes neuronales convolucionales</font></h1>



<h1><font color="#113D68" size=6>Caso Práctico: análisis de un problema de clasificación de imágenes con Deep Learning</font></h1>


<br><br>
<div style="text-align: right">
<font size=3>Daniel González</font><br>
<font size=3>IEBS</font>
</div>

---

<a id="indice"></a>
<h2><font color="#004D7F" size=5>Índice</font></h2>

* [Caso práctico](#section1)
    - [Parte obligatoria](#section1.1)
    - [Parte opcional](#section1.2)
    - [Objetivos](#section1.3)
    - [Criterios de entrega](#section1.4)
    - [Temporalización](#section1.5)
* [Flickr Style dataset](#section2)
* [Red convolucional desde 0](#section3)
    - [Ejercicio 1](#section3.1)
    - [Ejercicio 2](#section3.2)
* [Red pre-entrenada (InceptionV3)](#section4)
    - [Ejercicio 3](#section4.1)
    - [Ejercicio 4](#section4.2)
    - [Ejercicio 5](#section4.3)
    - [Ejercicio 6](#section4.3)
    - [Ejercicio 7](#section4.4)
    - [Ejercicio 8](#section4.5)
* [Red opcional](#section5)
    - [Ejercicio 7](#section5.1)
* [¿Cuál es el mejor modelo?](#section6)
    - [Ejercicio 8](#section6.1)
"""

!pip install tensorflow-addons

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

from keras.models import load_model
from keras.preprocessing.image import img_to_array
from tensorflow.keras import layers
from tensorflow.keras import models
from tensorflow.keras.models import Model
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.applications.inception_v3 import preprocess_input

# Para mostrar gráficas
import matplotlib.pyplot as plt
# %matplotlib inline

# Anaconda fixing problem
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'

# Establecemos una semilla para numpy y tensorflow para poder reproducir la ejecución y los resultados
seed = 101
np.random.seed(seed)
tf.random.set_seed(seed)

"""# <font color="#004D7F" size=5>Caso práctico</font>

El objetivo de este caso práctico es simular como se haría un análisis completo de un problema de clasificación de imágenes para resolverlo con Deep Learning. Nos pondremos en la piel de un *data scientist* dedicado a analizar y crear modelos de Deep Learning para pasarlos a producción y ser desplegados en una aplicación.

**Destacar que este caso práctico es la continuación de la actividad de la semana 2. En la actividad de la semana 2 utilizamos el modelo pre-entrendo de InceptionV3 y ahora vamos a realizar más experimentos usando redes convolucionales diseñadas por vosotros.**

Imaginemos que tenemos un dataset completo que queremos explotar, nuestra labor será coger este dataset (Flickr Style dataset) y desde 0 intentar llegar a conseguir un modelo que tenga un buen rendimiento ajustándolo poco a poco como hemos visto en clase. Por lo que tendremos que entrerar distintas redes y comparar los resultados que obtengamos en cada experimento para ver cual es mejor.

Cada experimento que tendremos que realizar estará bien definido, la red que deberéis crear y entrenar será proporcinada por lo que solamente tendréis que crear la red que se nos indica con TensorFlow y realizar el entrenamiento de la misma.

## <font color="#004D7F" size=4>Parte obligatoria</font>

Será obligatorio realizar cada uno de los ejercicios que están definidos. En cada ejercicio está definida la red que se tiene que crear y la configuración con la que se tiene que entrenar, por lo que solamente tendréis que pasar esa definición a código con TensorFlow.

Para tener una buena práctica en la realización de este caso práctico se ofrecen esta recomendaciones:

- Utiliza correctamente el sistema de celdas de jupyter. La libreta está realizada de tal forma que solo tendréis que completar las celdas que se indican, ya sea con código o con texto en markdown. Se recomienda rellenar solamente las celdas indicadas para que quede un informe limpio y fácil de seguir. Si fuera necesario incluir más celdas por cualquier motivo se puede hacer pero realizarlo con cuidado para no ensuciar demasiado la libreta.
<br><br>
- Las redes que tendréis que crear en cada experimento son las vistas en clase, por lo que os podéis inspirar en los ejemplos vistos en los tutoriales. Os recomiendo que no copiéis y peguéis código tal cual, sino que lo escribáis por vuestra cuenta y entendáis lo que estáis haciendo en cada momento. Tomaros el tiempo que haga falta para entender cada paso.
<br><br>
- Comprueba que todo se ejecuta correctamente antes de enviar tu trabajo. La mejor forma de enviarlo es exportando la libreta a pdf o html para enviarla en un formato más profesional.

## <font color="#004D7F" size=4>Parte opcional</font>
La parte opcional es el penúltimo ejercicio donde tendréis volver a aplicar la técnica de _fine-tuning_ eligiendo la red pre-entrenada que vosotros queráis y añadiendo las capas que vosotros elijáis.

## <font color="#004D7F" size=4>Objetivos</font>
* Cargar y entender los datos del dataset Flickr Style con los que se trabajarán.
* Crear cada una de las redes indicadas en los experimentos.
* Entrenar cada una de las redes creadas en los experimentos.
* Entender los resultados obtenidos en cada entrenamiento.

## <font color="#004D7F" size=4>Criterios de entrega</font>
Se deberá entregar una libreta de jupyter, aunque se agradecerá que el formato entregado se html o pdf, el trabajo debe estar autocontenido, incluyendo código y texto explicativo para cada sección.

<a id="section2"></a>
# <font color="#004D7F" size=5>Flickr Style dataset</font>

Este dataset es el que hemos visto en clase y con el que trabajaremos en el caso práctico. Para refrescarlo, es un dataset que contiene imágenes en color donde queremos clasificar cada imagen según el estilo fotográfico al que pertenece.

El dataset de de imágenes Flickr Style tiene las siguintes características:
- Imágenes de 5 tipos de estilo: Detailed, Pastel, Melancholy, Noir y HDR.
- Imágenes en color, es decir, cada pixel tiene 3 valores entre 0 y 255, esos valores corresponden a los valores de RGB (Red, Green, Blue).
- Imágenes de diferentes tamaños, por lo que tendremos que redimensionarlas al mismo tamaño todas antes de usarlas en nuestro modelo.
- 2.000 imágenes en total para el entrenamiento y para el test.

#### **Imporante!!! Solo ejecutar esta celda una sola vez para descargar los datos, no ejecutarlas si ya tenéis los datos descargados**
"""

!wget 'https://www.dropbox.com/s/ln92e9givhgzugr/flickr_style.zip?dl=0' -O flickr_style.zip
!unzip -q flickr_style.zip
!mkdir data
!mv flickr_style data/

"""Vamos a cargar los datos de las labels y los datos de las rutas de las imágenes:"""

# obtenemos el nombre de las primeras etiquetas seleccionadas
style_label_file = 'data/flickr_style/style_names.txt'
style_labels = list(np.loadtxt(style_label_file, str))
style_labels

# cargamos los datos de train
train_frame = pd.read_csv('data/flickr_style/train.txt', sep=" ", header=None)
train_frame.columns = ['files','labels_idx']
train_frame['labels'] = train_frame['labels_idx'].map({i:j for i,j in enumerate(style_labels)})

train_frame.head()

# cargamos los datos de test
test_frame = pd.read_csv('data/flickr_style/test.txt', sep=" ", header=None)
test_frame.columns = ['files','labels_idx']
test_frame['labels'] = test_frame['labels_idx'].map({i:j for i,j in enumerate(style_labels)})

test_frame.head()

# Mostramos 5 imágenes de cada clase.
plot_n_images = 5
fig = plt.figure(figsize=(20, 25))

np.random.seed(1000)
for i in range(0,5):
    select_frame = train_frame[train_frame['labels_idx']==i]
    for j in range(0,plot_n_images):
        aux_index = np.random.choice(select_frame.index)
        fig_i=fig.add_subplot(plot_n_images,5,j*5+i+1)
        fig_i.imshow(plt.imread(train_frame['files'][aux_index]))

        fig_i.set_xticks(())
        fig_i.set_yticks(())

    fig_i.set_xlabel('Class %s' % style_labels[i])

"""<a id="section3"></a>
# <font color="#004D7F" size=5>Red convolucional desde 0</font>

Los primeros experimentos que vamos a realizar será utilizando redes que creemos nosotros mismos. Para ello vamos a tener que transformar las imágense al igual que hicimos en clase, pero esta vez solamente tendremos que realizar estos pasos:

1. Cargar las imágenes
2. Redimensionar todoas las imágenes para tener el mismo tamaño. Usaremos un tamaño de `(150, 150, 3)`.

Como véis, al usar nuestras redes desde 0 no será necesario usar la función `preprocess_input` que tenemos que usar al usar una red pre-entrenada.

La función para transformar las imágenes sería la siguientes:
"""

def load_img(img_path):
    # cargamos y redimensionamos una imágen
    img = tf.keras.utils.load_img(
        img_path,
        target_size=(150, 150, 3)
    )

    # cambiamos el tipo imagen a un numpy.array
    img_array = tf.keras.preprocessing.image.img_to_array(img)

    # normalizamos los valores entre 0 y 1
    return img_array / 255

"""Ahora vamos a cargar las imágenes para poder entrenar nuestras redes convolucionales:"""

# cargamos las imágenes ya transformadas
x_train = np.array([load_img(img_path) for img_path in train_frame['files']])
x_test = np.array([load_img(img_path) for img_path in test_frame['files']])

# cargamos las clases de cada imagen
y_train = train_frame['labels_idx']
y_test = test_frame['labels_idx']

"""<a id="section3.1"></a>
### <font color="#004D7F" size=4>Ejercicio 1</font>

Crear una red con la siguiente configuración y entrénala:

Arquitectura de la red:

- Capa convolucional `Conv2D` con 16 filtros/kernels de tamaño `(3,3)`, padding con relleno, activación *ReLU* y con entrada `(150,150,3)`
- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.
- Capa de aplanado `Flatten`.
- Capa densa `Dense` con 64 neuronas y función de activación _ReLU_.
- Capa densa `Dense` con 32 neuronas y función de activación _ReLU_.
- Capa de salida densa `Dense` con 5 neuronas y función de activación _Softmax_.

Configuración del entrenamiento:

- Optimizador: Adam con factor de entrenamiento 0.001
- Función de error: `sparce_categorical_crossentropy`.
- Métricas: `accuracy`.
- Número de _epochs_: 10
- Validation split: 0.2
"""

# Definir la arquitectura de la red
mod_2 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(150, 150, 3)), # Capa Conv2D
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'), # Capa MaxPooling2D
    tf.keras.layers.Flatten(), # Capa Flatten
    tf.keras.layers.Dense(64, activation='relu'), # Capa Dense con 64 neuronas
    tf.keras.layers.Dense(32, activation='relu'), # Capa Dense con 32 neuronas
    tf.keras.layers.Dense(5, activation='softmax') # Capa de salida con 5 neuronas
])

# Resumen del modelo
mod_2.summary()

############################################################################################################
# Definir el optimizador
opt_mod2 = tf.keras.optimizers.Adam(learning_rate=0.001) # Optimizador Adam

# Compilar el modelo
mod_2.compile(
    optimizer=opt_mod2,
    loss='sparse_categorical_crossentropy', # Función de pérdida
    metrics=['accuracy'] # Métrica de evaluación
)

"""Evalua el modelo con el conjunto de test y muestra en una gráfica la evolución del entrenamiento:"""

# Entrenar el modelo con los datos de entrenamiento y validación
history_mod_2 = mod_2.fit(
    x_train, y_train, # Conjunto de entrenamiento
    validation_split=0.2, # Conjunto de validación
    epochs=10, # Número de épocas

)

# Evaluar el modelo en el conjunto de prueba
test_loss, test_accuracy = mod_2.evaluate(x_test, y_test, verbose=2)
print(f"Pérdida en el conjunto de prueba: {test_loss:.4f}")
print(f"Precisión en el conjunto de prueba: {test_accuracy:.4f}")

# Crear la figura y los subplots
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Gráfico de Precisión
axes[0].plot(history_mod_2.history['accuracy'], label='accuracy')
axes[0].plot(history_mod_2.history['val_accuracy'], label='val_accuracy')
axes[0].set_title('Evolución de la Precisión - mod_2')
axes[0].set_xlabel('Épocas')
axes[0].set_ylabel('Precisión')
axes[0].legend()
axes[0].grid(True)

# Gráfico de Pérdida
axes[1].plot(history_mod_2.history['loss'], label='loss')
axes[1].plot(history_mod_2.history['val_loss'], label='val_loss')
axes[1].set_title('Evolución de la Pérdida - mod_2')
axes[1].set_xlabel('Épocas')
axes[1].set_ylabel('Pérdida')
axes[1].legend()
axes[1].grid(True)

# Mostrar las gráficas
plt.tight_layout()
plt.show()

"""Escribe un pequeño texto sacando conclusiones de los resultado obtenidos:

Podemos ver que existe una gran diferencia entre el accuracy de entrenamiento (95.13%) y el de validación (43.68%), lo que nos indica mas de seguro que es un sobreajuste. En este caso se puede ver que está memorizando datos de entrenamiento en lugar de generalizar. Tambien se ve que la pérdida de entrenamiento es baja (0.2806), mientras que la de validación es alta (1.6844).Sin duda un sobre ajuste. Ademas comparado con los de test sus numeros estarian en rojo 39.38% con valor de perdida loss: 1.8860

<a id="section3.2"></a>
### <font color="#004D7F" size=4>Ejercicio 2</font>

Crear una red con la siguiente configuración y entrénala:

Arquitectura de la red:

- Capa convolucional `Conv2D` con 64 filtros/kernels de tamaño `(3,3)`, padding con relleno, activación *ReLU* y con entrada `(150,150,3)`
- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.
- Capa convolucional `Conv2D` con 32 filtros/kernels de tamaño `(3,3)`, padding con relleno, activación *ReLU*
- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.
- Capa convolucional `Conv2D` con 32 filtros/kernels de tamaño `(3,3)`, padding con relleno, activación *ReLU*
- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.
- Capa de aplanado `Flatten`.
- Capa densa `Dense` con 64 neuronas y función de activación _ReLU_.
- Capa `Dropout` con un valor de `0.75`.
- Capa densa `Dense` con 32 neuronas y función de activación _ReLU_.
- Capa densa `Dense` con 32 neuronas y función de activación _ReLU_.
- Capa `Dropout` con un valor de `0.6`.
- Capa de salida densa `Dense` con 10 neuronas y función de activación _Softmax_.

Configuración del entrenamiento:

- Optimizador: Adam con factor de entrenamiento 0.001
- Función de error: `sparce_categorical_crossentropy`.
- Métricas: `accuracy`.
- Número de _epochs_: 50
- Validation split: 0.2
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Definir la arquitectura del modelo
mod_3 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(150, 150, 3)), # Capa Conv2D con 64 filtros
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'), # Primera capa MaxPooling2D
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'), # Capa Conv2D con 32 filtros
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'), # Segunda capa MaxPooling2D
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'), # Otra capa Conv2D con 32 filtros
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'), # Tercera capa MaxPooling2D
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'), # Otra capa Conv2D con 64 filtros
    tf.keras.layers.Dropout(0.75),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.6),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Resumen del modelo
mod_3.summary()

from tensorflow.keras.optimizers import Adam
# Compilación del modelo
mod_3.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)



# Entrenar el modelo con los datos de entrenamiento y validación
history_mod_3 = mod_3.fit(
    x_train, y_train, # Conjunto de entrenamiento
    validation_split=0.2, # Conjunto de validación
    epochs=50, # Número de épocas
)

"""Evalua el modelo con el conjunto de test y muestra en una gráfica la evolución del entrenamiento:"""

# Evaluar el modelo en el conjunto de prueba
test_loss3, test_accuracy3 = mod_3.evaluate(x_test, y_test, verbose=2)
print(f"Pérdida en el conjunto de prueba: {test_loss3:.4f}")
print(f"Precisión en el conjunto de prueba: {test_accuracy3:.4f}")

# Crear la figura y los subplots
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Gráfico de Precisión
axes[0].plot(history_mod_3.history['accuracy'], label='accuracy')
axes[0].plot(history_mod_3.history['val_accuracy'], label='val_accuracy')
axes[0].set_title('Evolución de la Precisión - mod_2')
axes[0].set_xlabel('Épocas')
axes[0].set_ylabel('Precisión')
axes[0].legend()
axes[0].grid(True)

# Gráfico de Pérdida
axes[1].plot(history_mod_3.history['loss'], label='loss')
axes[1].plot(history_mod_3.history['val_loss'], label='val_loss')
axes[1].set_title('Evolución de la Pérdida - mod_2')
axes[1].set_xlabel('Épocas')
axes[1].set_ylabel('Pérdida')
axes[1].legend()
axes[1].grid(True)

# Mostrar las gráficas
plt.tight_layout()
plt.show()

"""Escribe un pequeño texto sacando conclusiones de los resultado obtenidos:

Si bien el modelo 3 o Mod_3  reduce el sobreajuste si lo comparamos con el modelo 2 o mod_2. la precisión es de 0.7058 y tiene una pérdida de 0.7673 en el conjunto de entrenamiento, mientras que en el conjunto de test se reportó una precisión de accuracy: 0.4906  y un loss: 2.5468. No es un buen modelo o le falta aun mas suavizado.

<a id="section4"></a>
# <font color="#004D7F" size=5>Red pre-entrenada (InceptionV3)</font>

Ahora vamos a realizar experimento usando la técnica de _fine-tuning_ y utilizando el modelo pre-entrenado de [_InceptionV3_](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3).

Los ejercicios siguientes podéis observar que son los mismos ejercicios de la actividad de la semana 2.

<a id="section4.1"></a>
## <font color="#004D7F" size=4>Ejercicio 3: preprocesamiento de las imágenes</font>
Como vamos a usar un modelo pre-entreando tenemos que definir la función que nos transforme las imágenes a utilizar. Como hemos visto en clase, para utilizar las imágenes usando un modelo pre-entrenado es necesario realizar una transformación sobre las imágenes que vamos a utilizar, es decir, tenemos que:

1. Cargar las imágenes
2. Redimensionarlas
3. Usar la función de `preprocess_input` del modelo pre-entrenado que vamos a utilizar.

En este caso vamos a utilizar otro modelo pre-entrado entre los que están disponibles en `tf.keras`, esta vez vamos a usar el modelo de _InceptionV3_, um modelo muy popular y usando frecuentemente. Podéis ver toda la información de este modelo [aquí](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3). Este modelo utilizar un tamaño de imagen de _**(299, 299, 3)**_, por lo que tendrás que usar este tamaño en el redimensionamiento.

Como hemos hecho en clase, define una función que se llame `load_img_inceptionv3(img_path)` a la cual le pasamos la ruta donde está alojada una imagen y le realiza todas las transformación necesarias para poder se utilizada luego en el proceso de entrenamiento.
"""

def load_img_inceptionv3(img_path):
    # Cargamos y redimensionamos la imagen a (299, 299, 3) que es el tamaño requerido por InceptionV3
    img = tf.keras.utils.load_img(
        img_path,
        target_size=(299, 299, 3)
    )

    # Convertimos la imagen a un array de numpy
    img_array = tf.keras.preprocessing.image.img_to_array(img)

    # Aplicamos la función de preprocesamiento específica de InceptionV3
    img_preprocessed = tf.keras.applications.inception_v3.preprocess_input(img_array)

    return img_preprocessed

"""**Test**: Puedes probar esta función con el siguiente test, cuando la tengas definida ejecuta la siguiente celda y te debería dar como resultado:

```python
-0.5529412
```
"""

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.inception_v3 import preprocess_input
img = load_img_inceptionv3('data/flickr_style/images/2216312257_2ba4af8439.jpg')
img[0,0,0]

"""<a id="section4.2"></a>
## <font color="#004D7F" size=4>Ejercicio 4: aplicar el preprocesamiento a todas las imágenes</font>
Una vez tenemos definida nuestra función de para transformar las imágenes, aplíca la transformación tanto al conjunto de train como al conjunto de test como hemos visto en clase.
"""

# Cargar todas las imágenes de entrenamiento y prueba usando la función para InceptionV3
x_train = np.array([load_img_inceptionv3(img_path) for img_path in train_frame['files']])
x_test = np.array([load_img_inceptionv3(img_path) for img_path in test_frame['files']])

# Cargar las clases correspondientes
y_train = np.array(train_frame['labels_idx'])  # Usamos las etiquetas como índices
y_test = np.array(test_frame['labels_idx'])

# Verificamos la forma de los arrays
print(f"x_train shape: {x_train.shape}")
print(f"x_test shape: {x_test.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape: {y_test.shape}")

"""**Test**: Puedes probar si lo has hecho correctamente con el siguiente test, cuando hayas terminado ejecuta la siguiente celda y te debería dar como resultado:

```python
(array([-0.5529412, -0.5529412, -0.5372549], dtype=float32), 3)
```
"""

x_train[0,0,0], y_train[0]

"""<a id="section4.3"></a>
## <font color="#004D7F" size=4>Ejercicio 5: cargar el modelo pre-entrenado InceptionV3</font>
Una vez tenemos los datos listos, vamos a cargar el modelo pre-entrenado de [_InceptionV3_](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3).

Como vamos a aplicar _fine-tuning_ recuerda usar los siguientes parámetros:
- `input_shape=(299, 299, 3)`
- `include_top=False`
- `pooling='avg'`

Además tienes que congelar todas las capas para que no se entrenen todas, recureda que solo queremos entrenar las últimas que añadamos nosotros.
"""

import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D

# Cargar el modelo pre-entrenado de InceptionV3
base_model5 = InceptionV3(
    weights='imagenet',  # Usamos los pesos pre-entrenados en ImageNet
    input_shape=(299, 299, 3),  # Tamaño de entrada requerido por InceptionV3
    include_top=False,  # Excluimos las capas densas superiores
    pooling='avg'  # Usamos Average Pooling al final
)

# Congelar todas las capas del modelo base
for layer in base_model5.layers:
    layer.trainable = False

"""**Test**: Puedes probar si lo has hecho correctamente con el siguiente test, cuando hayas terminado ejecuta la siguiente celda y te debería dar como resultado:

```python
[<keras.layers.merge.Concatenate at **************>,
 <keras.layers.pooling.GlobalAveragePooling2D at **************>]
```
"""

base_model5.layers[-2:]

"""### Conclusión
El modelo preentrenado InceptionV3 se configura de manera adecuada, el modelo esta congelado y preservan las características aprendidas durante su entrenamiento previo, maximizando la capacidad de transferir ese conocimiento.

Las capas superiores personalizadas, incluyendo Concatenate y GlobalAveragePooling2D, han sido integradas y están listas para generar embeddings representativos que sirven como base sólida para el entrenamiento de nuevas capas personalizadas para la clasificación de estilos fotográficos de manera eficiente.

<a id="section4.4"></a>
## <font color="#004D7F" size=4>Ejercicio 6: añadir capas al modelo (_fine-tuning_)</font>
Una vez tenemos nuestro modelo base, vamos a añadir capas densas al final para entrenarlas y que el modelo se ajuste a nuestros datos.

Añade las siguientes capas al modelo base cargado:
- Capa Dropout con un valor de 0.60.
- Capa Densa de 128 neuronas y función de activación `relu`.
- Capa Dropout con un valor de 0.4.
- Capa Densa de salida con 5 neuronas y función de activación `softmax`.
"""

# Completar
# Cargar el modelo base InceptionV3
base_model5 = tf.keras.applications.InceptionV3(
    input_shape=(299, 299, 3),  # Tamaño de entrada requerido por InceptionV3
    include_top=False,          # Excluir las capas densas superiores
    weights='imagenet',         # Usar pesos preentrenados de ImageNet
    pooling='avg'               # Aplicar Average Pooling al final
)

# Congelar el entrenamiento en todas las capas del modelo base
for layer in base_model5.layers:
    layer.trainable = False

# Añadir capas personalizadas al modelo
x = base_model5.output
x = Dropout(0.6, name="dropout")(x)  # Dropout con tasa de 0.6
x = Dense(128, activation='relu', name="dense")(x)  # Capa Densa de 128 neuronas con ReLU
x = Dropout(0.4, name="dropout_1")(x)  # Dropout con tasa de 0.4
predictions = Dense(5, activation='softmax', name="dense_1")(x)  # Capa de salida con 5 clases y softmax

# Crear el modelo completo
model5= tf.keras.Model(inputs=base_model5.input, outputs=predictions)

"""**Test**: Puedes probar si lo has hecho correctamente con el siguiente test, cuando hayas terminado ejecuta la siguiente celda y te debería dar como resultado:

```python
[<keras.layers.core.dropout.Dropout at **************>,
 <keras.layers.core.dense.Dense at **************>,
 <keras.layers.core.dropout.Dropout at **************>,
 <keras.layers.core.dense.Dense at **************>]
```
"""

model5.layers[-4:]

"""### Conclusión
Se añadieron nuevas capas al modelo InceptionV3, estas nuevas capas son  regularizaciones como Dropout y una capa de salida con activación softmax, diseñada para clasificar en 5 categorías correspondientes a los estilos fotográficos. al igual que el anterior las capas del modelo base permanecen congeladas, garantizando la preservación de los pesos preentrenados durante el entrenamiento del modelo y se le suman las nuevas tranformaciones para hacerlo mas preciso.

<a id="section4.5"></a>
## <font color="#004D7F" size=4>Ejercicio 7: entrenar el modelo</font>
Una vez tenemos nuestro modelo listo para entrenar, vamos a configurar el entrenamiento y a entrenar nuesto modelo.

En el entrenamiento utiliza:
- Optimizador: Adam con learning rate de 0.001.
- Función de coste: `sparse_categorical_crossentropy`.
- Métricas: `accuracy`.
- Epochs: `25`
- validation_split: 0.2
"""

# Configurar el modelo para el entrenamiento
model5.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Entrenar el modelo
history5 = model5.fit(
    x_train, y_train,  # Datos de entrenamiento
    validation_split=0.2,  # 20% del conjunto para validación
    epochs=25,  # Número de épocas
)

"""El modelo 7 es capaz de clasificar correctamente el 71.27% de las muestras en el conjunto de entrenamiento. La pérdida en el conjunto de entrenamiento es de 0.7052.  

Por otro lado la precisión del modelo en el conjunto de validación es del 60.29%, siendo la pérdida en el conjunto de validación de 1.0277. Esto validado con el 20% de los datos de entrenamiento .

El modelo 7 es coherente y logra generalizar datos no vistos aunque no de la mejor manera. Diria que tiene un sobreajuste pequeño, pero se puede ver que tiene una buena conducta.

<a id="section4.6"></a>
## <font color="#004D7F" size=4>Ejercicio 8: evaluar el modelo</font>
Una vez entrenado el modelo usando _fine-tuning_ evalua el modelo usando el conjunto de test en la función `evaluate` y extráe conlcusiones de si el modelo tiene un buen rendimiento o no. Puedes visualizar como ha ido el entrenamiento usando una gráfica como hemos visto en clase.
"""

# Evaluar el modelo en el conjunto de test (sin fine tuning)
test_loss5, test_accuracy5 = model5.evaluate(x_test, y_test, verbose=1)

# Mostrar los resultados
print(f"Test Loss sin fine tuning: {test_loss5}")
print(f"Test Accuracy sin fine tuning: {test_accuracy5}")

# Crear la figura y los subplots
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Gráfico de Precisión
axes[0].plot(history5.history['accuracy'], label='accuracy')
axes[0].plot(history5.history['val_accuracy'], label='val_accuracy')
axes[0].set_title('Evolución de la Precisión - mod_7')
axes[0].set_xlabel('Épocas')
axes[0].set_ylabel('Precisión')
axes[0].legend()
axes[0].grid(True)

# Gráfico de Pérdida
axes[1].plot(history5.history['loss'], label='loss')
axes[1].plot(history5.history['val_loss'], label='val_loss')
axes[1].set_title('Evolución de la Pérdida - mod_7')
axes[1].set_xlabel('Épocas')
axes[1].set_ylabel('Pérdida')
axes[1].legend()
axes[1].grid(True)

# Mostrar las gráficas
plt.tight_layout()
plt.show()

"""El modelo si bien no es tan bueno porque su accuracy en el test es del 55.94% lo que nos dice es que mas de la mitad de las imagenes son bien predichas.

Existe un accuracy de entrenamiento (71.27%) y el de validación con el 20% del conjunto que seria (60.29%) , lo que sugiere un ligero sobreajuste pero es mejor que los anteriores. Sin embargo, esta diferencia no es tan pronunciada, aunque es mejor en su generalización.

<a id="section5"></a>
# <font color="#004D7F" size=5>Red opcional</font>

<a id="section5.1"></a>
## <font color="#004D7F" size=4>Ejercicio 7</font>

En este ejercicio tienes vía libre para crear una red que tu creas que va a funcionar mejor. Puedes usar una red construida desde 0 que tu creas que funcionará mejor o puedes usar un modelo pre-entrenado entre los que puedes seleccionar en `tf._keras.applications` que puedes ver [aquí](https://www.tensorflow.org/api_docs/python/tf/keras/applications).

Usa las capas que tú quieras y la configuración de entrenamiento que tu elijas.

###Primer modelo Creativo con uso de InceptionV3
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

# Función para crear un módulo Inception eficiente
def create_efficient_inception_module(x, filters):
    # 1x1 convolution
    conv1x1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)

    # Factorized 3x3 convolution
    conv3x3 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)
    conv3x3 = layers.SeparableConv2D(filters, (3, 3), padding='same', activation='relu')(conv3x3)

    # Factorized 5x5 convolution (using two 3x3 convolutions)
    conv5x5 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)
    conv5x5 = layers.SeparableConv2D(filters, (3, 3), padding='same', activation='relu')(conv5x5)
    conv5x5 = layers.SeparableConv2D(filters, (3, 3), padding='same', activation='relu')(conv5x5)

    # Max pooling
    pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)
    pool = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(pool)

    # Concatenate all branches
    return layers.Concatenate()([conv1x1, conv3x3, conv5x5, pool])

# Función para crear el modelo con Transfer Learning
def create_model():
    # Modelo base preentrenado (InceptionV3)
    base_model = InceptionV3(include_top=False, input_shape=(299, 299, 3), weights='imagenet', pooling='avg')
    base_model.trainable = False  # Congela el modelo base

    # Añadir capas personalizadas
    x = base_model.output
    x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(5, activation='softmax')(x)

    # Crear el modelo
    modelX = models.Model(inputs=base_model.input, outputs=outputs)
    return modelX

# Compilar el modelo
modelX = create_model()
optimizer = Adam(learning_rate=0.001, weight_decay=1e-5)
modelX.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# Resumen del modelo
modelX.summary()

!mkdir -p data/train/{Detailed,Pastel,Melancholy,Noir,HDR} # crear estructura de directorio
# copiar imágenes a los subdirectorios correspondientes según las etiquetas
import shutil
for index, row in train_frame.iterrows():
    shutil.copy(row['files'], f"data/train/{row['labels']}/{row['files'].split('/')[-1]}")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # División para validación
)

train_generator = datagen.flow_from_dataframe(
    dataframe=train_frame,
    directory='.',
    x_col="files",
    y_col="labels",
    target_size=(299, 299),
    batch_size=32,
    class_mode='categorical',
    subset='training' # subset
)

val_generator = datagen.flow_from_dataframe(
    dataframe=train_frame,
    directory='.',
    x_col="files",
    y_col="labels",
    target_size=(299, 299),
    batch_size=45,
    class_mode='categorical',
    subset='validation' # subset
)

# Entrenamiento del modelo
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)

historyX = modelX.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15,
    callbacks=[early_stop, reduce_lr]
)

from tensorflow.keras.utils import to_categorical

# Convertir las etiquetas a one-hot encoding
y_test_one_hot = to_categorical(y_test, num_classes=5)

# Evaluar el modelo con las etiquetas en formato correcto
test_lossX, test_accuracyX = modelX.evaluate(x_test, y_test_one_hot, verbose=1)

# Mostrar los resultados
print(f"Test Loss sin fine tuning: {test_lossX}")
print(f"Test Accuracy sin fine tuning: {test_accuracyX}")

# Crear la figura y los subplots
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Gráfico de Precisión
axes[0].plot(historyX.history['accuracy'], label='accuracy')
axes[0].plot(historyX.history['val_accuracy'], label='val_accuracy')
axes[0].set_title('Evolución de la Precisión - mod_2')
axes[0].set_xlabel('Épocas')
axes[0].set_ylabel('Precisión')
axes[0].legend()
axes[0].grid(True)

# Gráfico de Pérdida
axes[1].plot(historyX.history['loss'], label='loss')
axes[1].plot(historyX.history['val_loss'], label='val_loss')
axes[1].set_title('Evolución de la Pérdida - mod_2')
axes[1].set_xlabel('Épocas')
axes[1].set_ylabel('Pérdida')
axes[1].legend()
axes[1].grid(True)

# Mostrar las gráficas
plt.tight_layout()
plt.show()

"""El modelo 8  que creamos con InceptionV3 muestra signos claros de sobreajuste (overfitting). La precisión que hay en el entrenamiento es de 70.29%, mientras que en el de test llega a duras penas a 58.84%.

No cree un buen modelo 8  ya que está memorizando los datos de entrenamiento  y no generaliza patrones.  La pérdida (loss) en el test (2.3146) es mayor que en entrenamiento (2.0016), dandonos a entender que existe un sobreajuste considerable sobreajuste.

 Los resultados en el conjunto nos da una presicion del 18.79% y una pérdida de 5.0936 es un modelo muy regular el modelo no ha capturado las características relevantes no sirve .

###Segundo modelo Creativo desde cero
"""

from sklearn.utils.class_weight import compute_class_weight

modelY = tf.keras.Sequential([

    # Primera capa convolucional
    tf.keras.layers.Conv2D(181, (5, 5), activation='relu', padding='same', input_shape=(150, 150, 3)),  # Capa Conv2D con 181 filtros
    tf.keras.layers.BatchNormalization(),  # Normalización por lotes
    tf.keras.layers.Activation('relu'),  # Activación ReLU
    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=3, padding='same'), # Primera capa MaxPooling2D

    # Segunda capa convolucional
    tf.keras.layers.Conv2D(73, (3, 3), activation='relu', padding='same'),  # Capa Conv2D con 32 filtros
    tf.keras.layers.BatchNormalization(),  # Normalización por lotes
    tf.keras.layers.Activation('relu'),  # Activación ReLU
    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=3, padding='same'), # Primera capa MaxPooling2D

    # Tercera capa convolucional
    tf.keras.layers.Conv2D(37, (3, 3), activation='relu', padding='same'),  # Capa Conv2D con 64 filtros
    tf.keras.layers.BatchNormalization(),  # Normalización por lotes
    tf.keras.layers.Activation('relu'),  # Activación ReLU
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'), # Tercera capa MaxPooling2D


    # Cuarta capa convolucional
    tf.keras.layers.Conv2D(83, (1, 1), activation='relu', padding='same'),  # Capa Conv2D con 83 filtros
    tf.keras.layers.BatchNormalization(),  # Normalización por lotes
    tf.keras.layers.Activation('relu'),  # Activación ReLU


    # Quinta capa convolucional
    tf.keras.layers.Conv2D(191, (3, 3), activation='relu', padding='same'),  # Capa Conv2D con 191 filtros
    tf.keras.layers.BatchNormalization(),  # Normalización por lotes
    tf.keras.layers.Activation('relu'),  # Activación ReLU

    # Segunda capa de MaxPooling
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'),  # MaxPooling2D para reducir la resolución

    # Capa de Global Average Pooling
    tf.keras.layers.GlobalAveragePooling2D(),  # Reduce las dimensiones espaciales a un vector de características

    # Primera capa densa
    tf.keras.layers.Dense(252, activation='relu'),  # Capa densa con 252 neuronas y activación ReLU
    tf.keras.layers.BatchNormalization(),  # Normalización por lotes
    tf.keras.layers.Dropout(0.5),  # Dropout para prevenir el sobreajuste

    # Segunda capa densa
    tf.keras.layers.Dense(127, activation='relu'),  # Capa densa con 127 neuronas y activación ReLU
    tf.keras.layers.BatchNormalization(),  # Normalización por lotes
    tf.keras.layers.Dropout(0.5),  # Dropout para prevenir el sobreajuste

    # Capa de salida
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')  # Capa de salida con 10 clases y activación softmax
])

# Balanceo de clases
class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(train_frame['labels_idx']),
    y=train_frame['labels_idx']
)
class_weights = dict(enumerate(class_weights))

# Resumen del modelo
modelY.summary()

import matplotlib.pyplot as plt
from tensorflow.keras import optimizers
from sklearn.model_selection import KFold
import numpy as np
from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint = ModelCheckpoint(
    f"model_fold{fold_no}.best.weights.h5",
    monitor='val_accuracy',
    save_best_only=True,
    save_weights_only=True,
    mode='max',
    verbose=1
)

# Supongamos que `x_train` y `y_train` son arrays de NumPy.
kf = KFold(n_splits=5, shuffle=True, random_state=123)
fold_no = 1

# Listas para almacenar los historiales de entrenamiento
histories = []

for train_index, val_index in kf.split(x_train):
    print(f"Entrenando el Fold {fold_no}...")

    # Crear subconjuntos de entrenamiento y validación
    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]
    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

    # Configurar el optimizador y compilar el modelo
    opt_modelY = optimizers.Adam(learning_rate=0.00001)  # Optimizador Adam
    modelY.compile(
        optimizer=opt_modelY,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    # Entrenar el modelo
    history_modelY = modelY.fit(
        x_train_fold, y_train_fold,
        validation_data=(x_val_fold, y_val_fold),
        epochs=37,
        batch_size=53,
        shuffle=True, callbacks=[checkpoint]
    )

    # Guardar el historial
    histories.append(history_modelY.history)

    print(f"Fold {fold_no} completado.")
    fold_no += 1

# Guardar los pesos del modelo dentro del loop
    modelY.save_weights(f"model_fold{fold_no}.weights.h5")

    # Guardar el historial
    histories.append(history_modelY.history)

print(f"Fold {fold_no} completado.")
fold_no += 1

# Crear la figura y los subplots para Accuracy
fig, axes = plt.subplots(1, 5, figsize=(20, 5)) #Se crean 5 subplots en axes
for i, history in enumerate(histories):
    if i < len(axes): #se verifica la longitud del index
        axes[i].plot(history['accuracy'], label='Train Accuracy') #si el index esta en el rango de axes imprime
        axes[i].plot(history['val_accuracy'], label='Val Accuracy')
        axes[i].set_title(f'Entrenamiento {i+1}')
        axes[i].set_xlabel('Épocas')
        axes[i].set_ylabel('Accuracy')
        axes[i].legend()
        axes[i].grid(True)
    else:
        break # si se alcanza el limite de subplots se sale
# Ajustar diseño y mostrar
plt.tight_layout()
plt.show()

# Crear la figura y los subplots para Loss
fig, axes = plt.subplots(1, 5, figsize=(20, 5)) #Se crean 5 subplots en axes
for i, history in enumerate(histories):
    if i < len(axes): #se verifica la longitud del index
        axes[i].plot(history['loss'], label='Train Loss') #si el index esta en el rango de axes imprime
        axes[i].plot(history['val_loss'], label='Val Loss')
        axes[i].set_title(f'Loss {i+1}')
        axes[i].set_xlabel('Épocas')
        axes[i].set_ylabel('Loss')
        axes[i].legend()
        axes[i].grid(True)
    else:
        break # si se alcanza el limite de subplots se sale
# Ajustar diseño y mostrar
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import ModelCheckpoint

# Configuración del fold a analizar
fold_no = 6  # Número de fold correcto según el mejor modelo guardado


# Restaurar los mejores pesos guardados durante el entrenamiento
try:
    modelY.load_weights(f"model_fold{fold_no}.weights.h5")
    print(f"Pesos del mejor modelo en el fold {fold_no} cargados exitosamente.")
except Exception as e:
    print(f"Error al cargar los pesos: {e}")
    raise

# Realizar predicciones en el conjunto de prueba
predictions = modelY.predict(x_test)
predicted_classY = np.argmax(predictions, axis=1)

# Visualizar 10 imágenes con predicciones
num_images = 5  # Número de imágenes a mostrar
indices = np.random.choice(len(x_test), num_images, replace=False)

plt.figure(figsize=(15, 10))
for i, idx in enumerate(indices):
    plt.subplot(2, 5, i + 1)
    plt.imshow(x_test[idx].squeeze(), cmap='gray')
    plt.title(f"Pred: {predicted_classY[idx]}\nTrue: {y_test[idx]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

"""El modelo, llamado modelY creado para este trabajo aparentemente es el modelo mejor ajustado, muestra una mejora progresiva a lo largo de los folds, tanto en precisión como en pérdida. nos dice que el modelo aprende los datos y generalizando bien.

Tambien se ve consistencia entre la precisión de entrenamiento y validación se mantiene eso quiere decir que es equilibrado alcanza una precisión de validación del 98.11%, quiere decir que es muy bueno, tambien hay que tener en cuenta que se entreno muchas veces para que llegara a ese nivel.

Se usan 37 epochs para la convergencia sin sobreajuste evidente, en el entrenamiento se ve que al modelo le cuesta mas aprender que reproducir, sugiere que los datos son dificiles, es robuzto y adaptable.

<a id="section6"></a>
# <font color="#004D7F" size=5>¿Cuál es el mejor modelo?</font>

<a id="section6.1"></a>
## <font color="#004D7F" size=4>Ejercicio 8</font>

Una vez realizado todos los experimentos anteriores, ¿qué modelo elegirías para desplegar en producción? ¿Por qué?

Explica en breves palabras qué modelo eligirías para desplegar en producción y porqué. Compara cada experimento y extráe tus propias conclusiones.


## Análisis comparativo

### Mod_2 y Mod_3
Estos modelos estan en sobreajuste, tienen diferencias significativas entre el rendimiento de entrenamiento y validación/test. El Mod_2 tiene un accuracy de entrenamiento del 95.13% pero solo 43.68% en validación, mientras que el Mod_3, aunque mejora ligeramente, aún muestra un rendimiento pobre en el conjunto de test (49.06% de accuracy).

### Mod_5
Aunque se implementaron técnicas de regularización como Dropout, el modelo es un precreado y de nombre InceptionV3, no se proporcionaron métricas específicas de rendimiento porque no se evaluo unicamente se menciona para dar credito a las personas que lo hacen

### Mod_7
Este modelo muestra una mejora en la generalización, con un accuracy de entrenamiento del 71.27% y 60.29% en validación o test. La brecha entre entrenamiento y validación es menor, ha mejorado los problemas del resto
### Mod_8
Presenta problemas de sobreajuste similares a Mod_2 y Mod_3, con un rendimiento en test muy bajito (18.79% de accuracy), lo que claramente descarta este modelo.

### Mod_9 o ModelY Como lo bautice
Este modelo destaca porque tiene:

1. **Mejora progresiva**:
2. **Alto rendimiento**
3. **Consistencia**
4. **Robustez**
5. **Convergencia estable**
6. **Hecho desde cero**

## Elección final: ModelY

Elegiría el Mod_9 (ModelY) para despliegue en producción por las siguientes razones:

1. **Rendimiento**
2. **Validación cruzada**
3. **Estabilidad**
4. **Potencial de generalización**:

En conclusión, ModelY demuestra las características interesantes, aunque hay que tener en cuenta que se entreno muchas veces para obtener ese resultado, esto quiere decir que puede fallar en un primer intneto, por el resto esta bien.
"""